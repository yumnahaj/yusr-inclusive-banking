import { useEffect, useRef, useState } from 'react';
import { Hands, Results } from '@mediapipe/hands';

export type GestureType = 'open_hand' | 'closed_fist' | 'pointing_right' | 'raised_hand' | 'ok_gesture' | 'none';

interface HandGestureRecognitionProps {
  onGestureDetected: (gesture: GestureType) => void;
  isActive: boolean;
  facingMode?: 'user' | 'environment';
}

export const useHandGestureRecognition = ({ onGestureDetected, isActive, facingMode = 'user' }: HandGestureRecognitionProps) => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const handsRef = useRef<Hands | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const animationRef = useRef<number | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [currentGesture, setCurrentGesture] = useState<GestureType>('none');
  const gestureCountRef = useRef<{ gesture: GestureType; count: number }>({ gesture: 'none', count: 0 });

  // Ø§ÙƒØªØ´Ø§Ù Ù†ÙˆØ¹ Ø§Ù„Ø¬Ù‡Ø§Ø²
  const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);

  // ØªØ­Ù„ÙŠÙ„ Ø¥ÙŠÙ…Ø§Ø¡Ø© Ø§Ù„ÙŠØ¯ Ù…Ø­Ø³Ù† Ù„Ù„Ø¬ÙˆØ§Ù„
  const analyzeGesture = (landmarks: any[]): GestureType => {
    if (!landmarks || landmarks.length === 0) return 'none';

    const hand = landmarks[0];
    if (!hand || hand.length < 21) return 'none';

    // Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„ÙŠØ¯
    const thumb_tip = hand[4];
    const thumb_mcp = hand[2];
    const index_tip = hand[8];
    const index_pip = hand[6];
    const index_mcp = hand[5];
    const middle_tip = hand[12];
    const middle_pip = hand[10];
    const ring_tip = hand[16];
    const ring_pip = hand[14];
    const pinky_tip = hand[20];
    const pinky_pip = hand[18];
    const wrist = hand[0];

    // Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£ØµØ§Ø¨Ø¹ Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø© Ù…Ø¹ ØªØ­Ø³ÙŠÙ† Ø£ÙƒØ¨Ø± Ù„Ù„Ø¬ÙˆØ§Ù„
    const mobileThreshold = isMobile ? 0.015 : 0.03; // Ø¹ØªØ¨Ø© Ø£Ù‚Ù„ Ù„Ù„Ø¬ÙˆØ§Ù„
    const mobileVerticalThreshold = isMobile ? 0.03 : 0.05; // Ø¹ØªØ¨Ø© Ø£Ù‚Ù„ Ù„Ù„Ø§Ø±ØªÙØ§Ø¹
    
    // Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø¨Ù‡Ø§Ù… Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© ÙˆØ§Ù„Ø®Ù„ÙÙŠØ©
    const thumb_ratio = facingMode === 'user' ? 
      (thumb_tip.x - thumb_mcp.x) : (thumb_mcp.x - thumb_tip.x);
    const isThumbUp = Math.abs(thumb_ratio) > mobileThreshold;
    
    // Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£ØµØ§Ø¨Ø¹ Ø§Ù„Ø£Ø®Ø±Ù‰ Ø¨Ø¹ØªØ¨Ø© Ø£Ù‚Ù„ Ù„Ù„Ø¬ÙˆØ§Ù„
    const isIndexUp = (index_mcp.y - index_tip.y) > mobileVerticalThreshold;
    const isMiddleUp = (middle_pip.y - middle_tip.y) > mobileVerticalThreshold;
    const isRingUp = (ring_pip.y - ring_tip.y) > mobileVerticalThreshold;
    const isPinkyUp = (pinky_pip.y - pinky_tip.y) > mobileVerticalThreshold;

    const fingersUp = [isThumbUp, isIndexUp, isMiddleUp, isRingUp, isPinkyUp].filter(Boolean).length;

    // Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªØ´Ø®ÙŠØµÙŠØ© Ù…ÙØµÙ„Ø©
    const debugInfo = {
      device: isMobile ? 'Mobile' : 'Desktop',
      facingMode,
      fingersUp,
      thumbRatio: thumb_ratio.toFixed(3),
      fingers: {
        thumb: isThumbUp,
        index: isIndexUp,
        middle: isMiddleUp,
        ring: isRingUp,
        pinky: isPinkyUp
      },
      thresholds: {
        mobile: mobileThreshold,
        vertical: mobileVerticalThreshold
      }
    };

    console.log('ğŸ” Detailed Gesture Analysis:', debugInfo);

    // ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥ÙŠÙ…Ø§Ø¡Ø§Øª Ù…Ø¹ Ø´Ø±ÙˆØ· Ø£ÙƒØ«Ø± ØªØ³Ø§Ù‡Ù„Ø§Ù‹ Ù„Ù„Ø¬ÙˆØ§Ù„
    if (fingersUp >= 4 || (isMobile && fingersUp >= 3 && isIndexUp && isMiddleUp)) {
      console.log('âœ‹ Detected: open_hand (fingers:', fingersUp, ')');
      return 'open_hand';
    } 
    
    if (fingersUp === 0 || (isMobile && fingersUp <= 1 && !isIndexUp)) {
      console.log('ğŸ‘Š Detected: closed_fist (fingers:', fingersUp, ')');
      return 'closed_fist';
    } 
    
    if (isIndexUp && !isMiddleUp && !isRingUp && !isPinkyUp) {
      console.log('ğŸ‘‰ Detected: pointing_right (index only)');
      return 'pointing_right';
    }
    
    if ((fingersUp === 3 && isIndexUp && isMiddleUp && isRingUp) || 
        (isMobile && fingersUp >= 2 && isIndexUp && isMiddleUp)) {
      console.log('ğŸ¤š Detected: raised_hand (3 fingers up)');
      return 'raised_hand';
    }
    
    if (isThumbUp && isIndexUp && fingersUp === 2) {
      const distance = Math.sqrt(
        Math.pow(thumb_tip.x - index_tip.x, 2) + 
        Math.pow(thumb_tip.y - index_tip.y, 2)
      );
      console.log('ğŸ‘Œ OK gesture check - distance:', distance.toFixed(3));
      if (distance < (isMobile ? 0.12 : 0.08)) { // Ø¹ØªØ¨Ø© Ø£ÙƒØ¨Ø± Ù„Ù„Ø¬ÙˆØ§Ù„
        console.log('ğŸ‘Œ Detected: ok_gesture');
        return 'ok_gesture';
      }
    }

    return 'none';
  };

  // Ù†Ø¸Ø§Ù… ØªØ£Ø®ÙŠØ± Ø§Ù„Ø¥ÙŠÙ…Ø§Ø¡Ø© Ù„Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±
  const lastGestureTime = useRef<number>(0);
  const gestureDebounce = 2000; // 2 Ø«Ø§Ù†ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ø¥ÙŠÙ…Ø§Ø¡Ø§Øª

  const onResults = (results: Results) => {
    if (!canvasRef.current) return;

    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    // Ù…Ø³Ø­ Ø§Ù„Ù„ÙˆØ­Ø©
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
      const gesture = analyzeGesture(results.multiHandLandmarks);
      
      // ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
      setCurrentGesture(gesture);
      
      // Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¥ÙŠÙ…Ø§Ø¡Ø© ÙÙˆØ±Ø§Ù‹ Ù…Ø¹ debouncing
      const now = Date.now();
      if (gesture !== 'none' && gesture !== currentGesture && 
          (now - lastGestureTime.current) > gestureDebounce) {
        
        console.log('ğŸ¯ Gesture detected immediately:', gesture);
        lastGestureTime.current = now;
        onGestureDetected(gesture);
        
        // Ø§Ù‡ØªØ²Ø§Ø² Ù„Ù„ØªØ£ÙƒÙŠØ¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¬ÙˆØ§Ù„
        if ('vibrate' in navigator && isMobile) {
          navigator.vibrate([100, 50, 100]);
        }
      }

      // Ø±Ø³Ù… Ø§Ù„Ù†Ù‚Ø§Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù„ÙˆØ­Ø© Ù„Ù„ØªØµØ­ÙŠØ­
      if (gesture !== 'none') {
        ctx.fillStyle = '#00ff00';
        ctx.strokeStyle = '#ff0000';
        ctx.lineWidth = 2;
        
        results.multiHandLandmarks.forEach((landmarks) => {
          // Ø±Ø³Ù… Ø§Ù„Ù†Ù‚Ø§Ø·
          landmarks.forEach((landmark, index) => {
            ctx.beginPath();
            ctx.arc(
              landmark.x * canvas.width,
              landmark.y * canvas.height,
              index === 8 || index === 4 ? 5 : 3, // Ù†Ù‚Ø§Ø· Ø£ÙƒØ¨Ø± Ù„Ù„Ø¥Ø¨Ù‡Ø§Ù… ÙˆØ§Ù„Ø³Ø¨Ø§Ø¨Ø©
              0,
              2 * Math.PI
            );
            ctx.fill();
          });
          
          // Ø±Ø³Ù… Ø®Ø·ÙˆØ· Ø§Ù„ÙŠØ¯
          const connections = [
            [0, 1], [1, 2], [2, 3], [3, 4], // Ø§Ù„Ø¥Ø¨Ù‡Ø§Ù…
            [0, 5], [5, 6], [6, 7], [7, 8], // Ø§Ù„Ø³Ø¨Ø§Ø¨Ø©
            [0, 9], [9, 10], [10, 11], [11, 12], // Ø§Ù„ÙˆØ³Ø·Ù‰
            [0, 13], [13, 14], [14, 15], [15, 16], // Ø§Ù„Ø¨Ù†ØµØ±
            [0, 17], [17, 18], [18, 19], [19, 20] // Ø§Ù„Ø®Ù†ØµØ±
          ];
          
          ctx.beginPath();
          connections.forEach(([start, end]) => {
            ctx.moveTo(
              landmarks[start].x * canvas.width,
              landmarks[start].y * canvas.height
            );
            ctx.lineTo(
              landmarks[end].x * canvas.width,
              landmarks[end].y * canvas.height
            );
          });
          ctx.stroke();
        });
      }
    } else {
      setCurrentGesture('none');
    }
  };

  const processFrame = async () => {
    if (handsRef.current && videoRef.current && videoRef.current.readyState === 4) {
      await handsRef.current.send({ image: videoRef.current });
    }
    if (isActive && handsRef.current) {
      animationRef.current = requestAnimationFrame(processFrame);
    }
  };

  const startCamera = async () => {
    if (!videoRef.current) return;

    try {
      setIsLoading(true);
      setError(null);

      // Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙƒØ§Ù…ÙŠØ±Ø§ Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ø¬ÙˆØ§Ù„
      let constraints;
      
      if (isMobile) {
        // Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø®Ø§ØµØ© Ù„Ù„Ø¬ÙˆØ§Ù„
        constraints = {
          video: {
            facingMode,
            width: { min: 320, ideal: 640, max: 1280 },
            height: { min: 240, ideal: 480, max: 720 },
            frameRate: { min: 10, ideal: 15, max: 20 },
            aspectRatio: { ideal: 4/3 }
          },
          audio: false
        };
      } else {
        // Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù„Ù„ÙƒÙ…Ø¨ÙŠÙˆØªØ±
        constraints = {
          video: {
            facingMode,
            width: { ideal: 640 },
            height: { ideal: 480 },
            frameRate: { ideal: 30 }
          },
          audio: false
        };
      }
      
      console.log('ğŸ“± Camera constraints for', isMobile ? 'mobile' : 'desktop', ':', constraints);

      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      streamRef.current = stream;
      
      videoRef.current.srcObject = stream;
      
      // Ø§Ù†ØªØ¸Ø§Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ© Ù„Ù„ÙÙŠØ¯ÙŠÙˆ
      await new Promise<void>((resolve, reject) => {
        if (!videoRef.current) {
          reject(new Error('Video ref is null'));
          return;
        }
        
        const video = videoRef.current;
        
        video.onloadedmetadata = () => {
          console.log('ğŸ“± Video metadata loaded:', {
            width: video.videoWidth,
            height: video.videoHeight,
            duration: video.duration
          });
          
          video.play().then(() => {
            console.log('ğŸ“± Video playback started');
            resolve();
          }).catch(reject);
        };
        
        video.onerror = () => {
          reject(new Error('Failed to load video'));
        };
        
        // timeout Ù„Ù„Ø£Ù…Ø§Ù†
        setTimeout(() => {
          reject(new Error('Video loading timeout'));
        }, 10000);
      });

  const hands = new Hands({
       locateFile: (file) => {
          return `https://lkgbogpytkwpdgwywrrz.supabase.co/storage/v1/object/public/hand//hands_solution_packed_assets.data${file}`;
       }
  });


      // Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª MediaPipe Ù…ÙØ­Ø³Ù†Ø© Ø®ØµÙŠØµØ§Ù‹ Ù„Ù„Ø¬ÙˆØ§Ù„
      let handsOptions;
      
      if (isMobile) {
        handsOptions = {
          maxNumHands: 1,
          modelComplexity: 0, // Ø£Ù‚Ù„ ØªØ¹Ù‚ÙŠØ¯ Ù„Ù„Ø¬ÙˆØ§Ù„
          minDetectionConfidence: 0.3, // Ø¹ØªØ¨Ø© Ø£Ù‚Ù„ Ù„Ù„Ø¬ÙˆØ§Ù„
          minTrackingConfidence: 0.3, // Ø¹ØªØ¨Ø© Ø£Ù‚Ù„ Ù„Ù„Ø¬ÙˆØ§Ù„
          selfieMode: facingMode === 'user'
        };
      } else {
        handsOptions = {
          maxNumHands: 1,
          modelComplexity: 1,
          minDetectionConfidence: 0.7,
          minTrackingConfidence: 0.5,
          selfieMode: facingMode === 'user'
        };
      }
      
      console.log('ğŸ¤– MediaPipe settings for', isMobile ? 'mobile' : 'desktop', ':', handsOptions);
      hands.setOptions(handsOptions);

      hands.onResults(onResults);
      handsRef.current = hands;

      // Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ù…Ø¹ Ù…Ø¹Ø¯Ù„ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø¬Ù‡Ø§Ø²
      processFrame();
      
      setIsLoading(false);
      console.log('âœ… Camera and MediaPipe initialized successfully for', isMobile ? 'mobile' : 'desktop');
      
    } catch (err) {
      console.error('âŒ Error starting camera:', err);
      let errorMessage = 'Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§';
      
      if (err instanceof Error) {
        console.error('Error details:', err.message);
        
        if (err.name === 'NotAllowedError' || err.message.includes('Permission')) {
          errorMessage = 'ØªÙ… Ø±ÙØ¶ Ø§Ù„Ø¥Ø°Ù† Ù„Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ØªØµÙØ­';
        } else if (err.name === 'NotFoundError' || err.message.includes('device')) {
          errorMessage = 'Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙƒØ§Ù…ÙŠØ±Ø§. ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ ÙƒØ§Ù…ÙŠØ±Ø§ Ù…ØªØµÙ„Ø©';
        } else if (err.name === 'NotSupportedError' || err.message.includes('support')) {
          errorMessage = 'Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…ØªØµÙØ­';
        } else if (err.name === 'OverconstrainedError' || err.message.includes('constraint')) {
          errorMessage = 'Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ØºÙŠØ± Ù…ØªÙˆØ§ÙÙ‚Ø©. Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø¨Ø³Ø·Ø©...';
          
          // Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø¨Ø³Ø·Ø©
          setTimeout(() => {
            startCameraWithBasicSettings();
          }, 1000);
          return;
        } else if (err.message.includes('timeout')) {
          errorMessage = 'Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§. ÙŠØ±Ø¬Ù‰ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©';
        }
      }
      
      setError(errorMessage);
      setIsLoading(false);
    }
  };

  // Ø¯Ø§Ù„Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù„Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø¨Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ©
  const startCameraWithBasicSettings = async () => {
    if (!videoRef.current) return;

    try {
      setError(null);
      setIsLoading(true);

      const basicConstraints = {
        video: true,
        audio: false
      };

      console.log('ğŸ“± Trying with basic camera settings');
      const stream = await navigator.mediaDevices.getUserMedia(basicConstraints);
      streamRef.current = stream;
      videoRef.current.srcObject = stream;
      
      await videoRef.current.play();

      // Ø¥Ø¹Ø¯Ø§Ø¯ MediaPipe Ø¨Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ©
      const hands = new Hands({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
      });

      hands.setOptions({
        maxNumHands: 1,
        modelComplexity: 0,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5,
        selfieMode: true
      });

      hands.onResults(onResults);
      handsRef.current = hands;
      processFrame();
      
      setIsLoading(false);
      console.log('âœ… Camera started with basic settings');
      
    } catch (err) {
      console.error('âŒ Even basic camera failed:', err);
      setError('ÙØ´Ù„ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø­ØªÙ‰ Ù…Ø¹ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©');
      setIsLoading(false);
    }
  };

  const stopCamera = () => {
    if (animationRef.current) {
      cancelAnimationFrame(animationRef.current);
      animationRef.current = null;
    }
    
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    
    if (videoRef.current) {
      videoRef.current.srcObject = null;
    }
    
    if (handsRef.current) {
      handsRef.current.close();
      handsRef.current = null;
    }
    
    setCurrentGesture('none');
  };

  useEffect(() => {
    if (isActive) {
      startCamera();
    } else {
      stopCamera();
    }

    return () => {
      stopCamera();
    };
  }, [isActive]);

  return {
    videoRef,
    canvasRef,
    isLoading,
    error,
    currentGesture,
    startCamera,
    stopCamera
  };
};
